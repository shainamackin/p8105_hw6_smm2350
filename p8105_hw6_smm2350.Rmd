---
title: "p8105_hw6_smm2350"
author: "Shaina Mackin"
date: "12/1/2021"
output: github_document
---

# Homework 6

To begin, I'll load libraries and set themes.

```{r setup, include = FALSE}
library(tidyverse)
library(dplyr)
library(rvest)
library(modelr)
library(mgcv) 

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

I'll first load the birthweight dataset...
```{r import1}
bwt_data = read.csv("/Users/shainamackin/Desktop/Fall 2021/Data Science I/p8105_hw6_smm2350/data/birthweight.csv")
```

... and then clean it by tidying variable names and factoring when relevant so that it's ready for regression analysis. 
```{r clean}
bwt_df = bwt_data %>%
  mutate(
    babysex = factor(babysex),
    frace = factor(frace),
    malform = factor(malform),
    mrace = factor(mrace)
  ) %>%
  mutate(
    babysex = fct_recode(babysex, "male" = '1'),
    babysex = fct_recode(babysex, "female" = '2'),
    frace = fct_recode(frace, "white" = '1'),
    frace = fct_recode(frace, "black" = '2'),
    frace = fct_recode(frace, "asian" = '3'),
    frace = fct_recode(frace, "puerto rican" = '4'),
    frace = fct_recode(frace, "other" = '8'),
    malform = fct_recode(malform, "absent" = '0'),
    malform = fct_recode(malform, "present" = '1'),
    mrace = fct_recode(mrace, "white" = '1'),
    mrace = fct_recode(mrace, "black" = '2'),
    mrace = fct_recode(mrace, "asian" = '3'),
    mrace = fct_recode(mrace, "puerto rican" = '4')
    ) %>%
  janitor::clean_names()

colSums(is.na(bwt_df))
```
Note: there are no missing values. 

I'll build a linear regression model for birthweight using backwards selection. First, I'll include all variables as predictors in my fully saturated model:  
```{r saturated}
saturated_fit = lm(bwt ~., data = bwt_df)

saturated_fit%>%broom::tidy()%>%knitr::kable()
```

Second, I'll run a backward selection using `stepAIC` from the `MASS` package to remove all non-significant predictors from the model. 
```{r proposed}
my_model = MASS::stepAIC(saturated_fit, direction = "backward", trace = FALSE)

my_model%>%broom::tidy() %>%knitr::kable()
```
All coefficients in this reduced model are now statistically significant. 

The [literature](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3390317/) confirms that smoking exposure, maternal weight, weight gain during pregnancy, and previous LBW babies are all associated with birthweight (Metgud et al., 2012). Race and income should also be kept in the model, as they are statistically significant and increasingly recognized as social determinants of maternal & neonatal health outcomes. We will also keep height, gestational age, baby's length, head circumference, and sex in the model, as they are statistically significant and clinically relevant to birthweight. 

`my_model` thus includes `babysex`, `bhead`, `blength`, `delwt`, `fincome`, `gaweeks`, `mheight`, `mrace`, `parity`, `ppwt`, and `smoken`.

I'll now create a plot of model residuals against fitted values. 
```{r plot}
bwt_resid = add_residuals(bwt_df, my_model) 

bwt_pred = add_predictions(bwt_df, my_model)


bwt_df %>%
  add_residuals(my_model) %>%
 add_predictions(my_model) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .5) +
  labs(
    x = "Predictions",
    y = "Residuals",
    title = "Predictions against Residuals in Proposed Regression Model"
  )
```

It's now time to use cross validation to compare my model to two others:
<br/>
• One using length at birth and gestational age as predictors (main effects only) <br/>
• One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r compare}
model_1 = lm(bwt ~ blength + gaweeks, data = bwt_df)
  
model_2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = bwt_df)

model_1%>%broom::tidy() %>%knitr::kable()
model_2%>%broom::tidy() %>%knitr::kable()
```

I’ll first add train and test to my cross validated data frame. Then, I'll use mutate + map & map2 to fit models to the training data and obtain corresponding RMSEs for the testing data. 
```{r cv1}
cv_df =
  crossv_mc(bwt_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df2 = cv_df %>% 
  mutate(
    my_model  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data =.x)),
     model_1      = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
     model_2      = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>%
  mutate(
    rmse_my_model = map2_dbl(my_model, test, ~rmse(model = .x, data = .y)),
    rmse_model_1  = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_model_2  = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)))
```

Next, I'll plot the prediction error distribution for each model. 
```{r cv2}
cv_df2 %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + 
  geom_violin(alpha=.5) +
  labs("RMSEs across candidate models")
```

The RMSE of `my_model` is the smallest, indicating that my originally proposed model (including sex, head circumference, length, delivery weight, income, gestational age, mother's height, mother's race, parity, pre-pregnancy weight, and smoking) is the best fitted model for our birthweight regression. `model_2` (including head circumference, length, sex, and all interactions between these) is the second best option, followed by `model_1` (including length at birth and gestational age as predictors). 

## Problem 2

I'll start by loading the 2017 Central Park weather data.
```{r import2}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Now, I'll use 5000 bootstrap samples to produce estimates for r̂^2 and log(β̂0hat∗β̂1hat).

I'll start by producing r^2hat estimates for each bootstrap sample. 
```{r r2_estimates}
set.seed(1)

weather_bootstrap_r2 = weather_df %>% 
  bootstrap(n = 5000) %>%
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>%
  select(-strap, -models) %>%
  unnest(results) %>%
  summarize(r.squared)

print(weather_bootstrap_r2)
```

Here are the r^2hat 95% CIs:
```{r r2_CIs}
weather_bootstrap_r2_ci = weather_df %>%
  bootstrap(n = 5000) %>%
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>%
  select(-strap, -models) %>%
  unnest(results) %>%
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975)) 

weather_bootstrap_r2_ci %>% knitr::kable(digits = 3)
```

Next, I'll produce log(β̂0∗β̂1) estimates for each bootstrap sample.
```{r log_estimates}
weather_bootstrap_log = weather_df %>%
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>%
  select(-strap, -models) %>%
  unnest(results) %>%
  select(.id, term, estimate) %>%
  mutate(term = if_else(term != "tmin", "intercept", "tmin")) %>% pivot_wider(
    names_from = term,
    values_from = estimate) %>%
  mutate(
    logb0b1 = log(intercept) + log(tmin)
    )
```

Here are the log(β̂hat0∗β̂hat1) 95% CIs: 
```{r log_CIs}
weather_bootstrap_log_ci = weather_df %>%
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>%
  select(-strap, -models) %>%
  unnest(results) %>%
  select(.id, term, estimate) %>%
  mutate(term = if_else(term != "tmin", "intercept", "tmin")) %>% pivot_wider(
    names_from = term,
    values_from = estimate) %>%
  mutate(
    logb0b1 = log(intercept) + log(tmin)
    ) %>%
  summarize(
    ci_lower = quantile(logb0b1, 0.025), 
    ci_upper = quantile(logb0b1, 0.975))

weather_bootstrap_log_ci %>% knitr::kable(digits = 3)
```

I'll also plot the distribution of these estimates below, starting with r^2...
```{r plot_estimates_r2}
weather_df %>% 
  bootstrap(n = 5000) %>%
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>%
  select(-strap, -models) %>%
  unnest(results) %>%
  ggplot(aes(x = r.squared)) +
  geom_density() + 
  labs(
    x = "R Squared",
    y = "Density",
    title = "Distribution of R Squared Estimates from Bootstrap Sample (n = 5000)"
  )
```

... and continuing with log(β̂hat0∗β̂hat):
```{r plot_estimates_log}
weather_df %>%
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>%
  select(-strap, -models) %>%
  unnest(results) %>%
  select(.id, term, estimate) %>%
  mutate(term = if_else(term != "tmin", "intercept", "tmin")) %>% pivot_wider(
    names_from = term,
    values_from = estimate) %>%
  mutate(
    logb0b1 = log(intercept) + log(tmin)
    ) %>%
  ggplot(aes(x = logb0b1)) +
  geom_density() + 
  labs(
    x = "Log(Beta0 * Beta1)",
    y = "Density",
    title = "Distribution of Log(Beta0 * Beta1) Estimates from Bootstrap Sample (n = 5000)"
  )
```

The distribution of r^2 is approximately normally distributed, though ever so slightly left skewed, which may be related to the frequency with which large outliers are included in the bootstrap sample. It is centered around 0.9125, approximately. <br/>
Similarly, the distribution of log(β̂hat0∗β̂ha) is approximately normally distributed, though also slightly left skewed, which - again - may be related to the frequency with which large outliers are included in the bootstrap sample. It is centered around 2.2, approximately. 